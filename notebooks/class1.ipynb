{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6522dbfa",
   "metadata": {},
   "source": [
    "# Graph Machine Learning Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2efa87",
   "metadata": {},
   "source": [
    "by Alejandro Correa Bahnsen, Jaime D. Acevedo-Viloria & Luisa Roa\n",
    "\n",
    "version 1.2, October 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1cac9",
   "metadata": {},
   "source": [
    "In this notebook we will be doing a brief introduction to graph machine learning. The agenda is as follows:\n",
    "\n",
    "\n",
    "1. Different types of graphs - Introduction to NetworkX\n",
    "2. Creating Graph Based Features and enhancing ML models\n",
    "3. Creating a Graph from own data using NetworkX\n",
    "4. Transductive Learning vs. Inductive Learning\n",
    "5. Graph Neural Networks - Introduction to DGL\n",
    "\n",
    "Through these basics you will be able to leverage graphs for the enhacement of Machine Learning models, or be able to learn the basics of how to build Neural Networks specially crafted for Graphs. We hope you like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install libraries\n",
    "!pip install dgl==0.6.1\n",
    "!pip install torch==1.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655eb36d",
   "metadata": {},
   "source": [
    "## Types of Graphs - An Introduction to NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee69b25",
   "metadata": {},
   "source": [
    "NetworkX according to it's creators is: NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. \n",
    "\n",
    "![](https://raw.githubusercontent.com/jdacevedo3010/graph-mahine-learning-workshop/master/images/networkx_description.png)\n",
    "\n",
    "https://networkx.org/\n",
    "\n",
    "We will be using the latest stable 2.8.7 version of the Package as referenced on the requirements .txt provided in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8343044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd87c3",
   "metadata": {},
   "source": [
    "Let's start by describing different properties graphs can have and what those mean for the graph in subject. We will use NetworkX visual examples for every one of them and we will also describe real world applications where you may find such type of graph.\n",
    "\n",
    "We will be using different NetworkX to innitialize graphs, this is just to highlight the many different ways we can do this. Make sure to check the documentation for more info in this: https://networkx.org/documentation/stable/reference/generators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af8b14",
   "metadata": {},
   "source": [
    "### Directed & Undirected Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e856bd",
   "metadata": {},
   "source": [
    "This property refers as to whether the edges connecting the graphs have an inherent direction in it.\n",
    "\n",
    "In undirected the graphs, edges indicate a two-way relationship, and as such they can be traversed from either node to other connected. In directed graphs, edges indicate a one-way direction. Meaning that they can only be traversed in an specific direction of the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilize a random graph\n",
    "g_gaussian = nx.gaussian_random_partition_graph(25, 4, 5, 0.25, 0.1, directed=False)\n",
    "\n",
    "#Draw the graph structure\n",
    "nx.draw(g_gaussian, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a random directed graph\n",
    "g_gaussian_dir = nx.gaussian_random_partition_graph(25, 4, 5, 0.25, 0.1, directed=True, seed=23)\n",
    "\n",
    "#Draw the graph structure\n",
    "nx.draw(g_gaussian_dir, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e2bd5",
   "metadata": {},
   "source": [
    "This is normally described by the use of an arrow pointing the direction of the edge, if there is no arrow then we can assume the graph is undirected. We can see this in the above networkX examples, where we create both a undirected and directed Random Gaussian Graph setting the directed parameter to True and False respectively.\n",
    "\n",
    "This is a very important characteristic in real life application. When creating graphs to describe real-life processes we might have an Instagram like Social Network, where an user can follow another user but it doesn't have to be the other way around. This would be a directed graph.\n",
    "\n",
    "We may also have a Facebook like Social Network, where when a friend request is sent and accepted both users are instantly connected to each other. This could be described by an undirected graph.\n",
    "\n",
    "We can also see this, when extracting the edges of the graph with the edges() method, take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35acb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_gaussian.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_gaussian_dir.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e00f86",
   "metadata": {},
   "source": [
    "This accesses the EdgeView for the undirected graphs where all edges are given as undirected. While, on the directed graph we can see that it defaults to the OutEdges of the graph, meaning that those tuples represent just a one-way path from one node to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e2677",
   "metadata": {},
   "source": [
    "### Weighted and Unweighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ac259",
   "metadata": {},
   "source": [
    "Another property that graphs can have is that they have edges with different weights, this means that in the relationship between two nodes there is a numerical value that indicates the magnitude of how strong or important the relationship is. In this way, weighted graphs are those that contain a weight on each edge while a unweighted graph does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9afc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Inicialize a random graph\n",
    "G=nx.gnm_random_graph(35, 50, seed=12)\n",
    "\n",
    "#Assign a random weights\n",
    "for (u, v) in G.edges():\n",
    "    G.edges[u,v]['weight'] = random.random()\n",
    "\n",
    "#Define type of relationship\n",
    "family = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] >= 0.6]\n",
    "friend = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] < 0.6]\n",
    "\n",
    "#Plot\n",
    "pos = nx.spring_layout(G, seed=124)\n",
    "nx.draw_networkx_nodes(G, pos)\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos, edgelist=family, width=2, edge_color='r', alpha = 0.4\n",
    ")\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos, edgelist=friend, width=1, edge_color='b', alpha = 0.4\n",
    ")\n",
    "\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.margins(0.08)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f0cf2",
   "metadata": {},
   "source": [
    "We create a graph with 35 nodes and 50 random edges with the gnm_random_graph function, then we assign the property 'weights' to the edges with a random probability. Lets now assume that it is a social network, where each node is a person who has different connections with friends or family, if the weight is greater than 0.6 then there is a closer connection so they are family, but if the weight is less than 0.6 then the relationship is less strong and they are friends.\n",
    "\n",
    "Although this is a simple example, in many real-world applications it is an important characteristic to consider since not all relatinoships are equal. Furthermore, different graphs algorithms are affected, for example in the shortest path algorith what used to be the shortest path can also be the most expensive given the weights in the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4de243",
   "metadata": {},
   "source": [
    "### Sparse & Dense Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e283a",
   "metadata": {},
   "source": [
    "This is an interesting distinction, the density of the graph refers to both the number of nodes and how connected are them. In mathematics, a dense graph is a graph in which the number of edges is close to the maximal number of edges. The maximal number of edges being all the pair combination of nodes in an undirected graph, and all the pair permutation of nodes in an undirected graph.\n",
    "\n",
    "In other words, the more close to fully connected the graph is - fully connected meaning that every node is connected to each other-, the more dense we can say the graph is. If the graph is a bunch of disjunct islands of nodes, we can safely say that is a sparse graph. Let's see some networkX examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c60df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of nodes n\n",
    "n = 25\n",
    "\n",
    "#Initialize the sparse graph\n",
    "g_sparse = nx.erdos_renyi_graph(n, 0.08,seed=23)\n",
    "\n",
    "#Draw the graph structure\n",
    "nx.draw(g_sparse, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8063f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dense graph\n",
    "g_dense = nx.erdos_renyi_graph(n, 0.15,seed=23)\n",
    "\n",
    "#Draw the graph structure\n",
    "nx.draw(g_dense, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8cdc6",
   "metadata": {},
   "source": [
    "We create the graphs using the generator method erdos_renyi_graph, this is a commonly used model to generate random graphs from two parameters: The number of nodes n, and the probability to create an edge for every pair of nodes p.\n",
    "\n",
    "Therefore, for the sparse graph we set up a small probability of 0.08, and for the dense graph we set up a probability of 0.15.\n",
    "\n",
    "We can also measure the Density of the graph, as the ratio of the number of edges with respect to the maximal number of edges. Therefore we can use the following formulas for undirected and directed graphs:\n",
    "\n",
    "Undirected: ![](https://raw.githubusercontent.com/jdacevedo3010/graph-mahine-learning-workshop/master/images/undirected.png)\n",
    "\n",
    "Directed: ![](https://raw.githubusercontent.com/jdacevedo3010/graph-mahine-learning-workshop/master/images/directed.png)\n",
    "\n",
    "Now, let's measure the density of the previously created graphs!\n",
    "\n",
    "First we need the number of edges for both graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_sparse = g_sparse.number_of_edges()\n",
    "e_dense = g_dense.number_of_edges()\n",
    "\n",
    "print(\"The number of edges for the sparse graph is: \", e_sparse)\n",
    "print(\"The number of edges for the dense graph is: \", e_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9065fc",
   "metadata": {},
   "source": [
    "As you can see we used the number_of_edges() method to measure how many edges we have in each graph automatically. Here we can see other properties we can take from NetworkX graphs: https://networkx.org/documentation/stable/reference/classes/graph.html.\n",
    "\n",
    "Like for example, wether a certain node or edge exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629d727",
   "metadata": {},
   "source": [
    "Now try to recreate the formula for undirected graphs in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95017b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_undirected_graph_density(g):\n",
    "    '''\n",
    "    Hint you should use the Graph Class attributes to get\n",
    "    the number of nodes and Edges\n",
    "    '''\n",
    "    n_nodes = 0 #Your code goes here instead of the zero\n",
    "    n_edges = 0 #Your code goes here instead of the zero\n",
    "    density = 0 #Your code goes here instead of the zero\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8946744",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_sparse = calculate_undirected_graph_density(g_sparse)\n",
    "density_dense = calculate_undirected_graph_density(g_dense)\n",
    "\n",
    "print(\"The density of the sparse graph is: \",round(density_sparse,2))\n",
    "print(\"The density of the dense graph is: \",round(density_dense,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64595d70",
   "metadata": {},
   "source": [
    "Now let's try the directed graph density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_directed_graph_density(g):\n",
    "    '''\n",
    "    Hint you should use the Graph Class attributes to get\n",
    "    the number of nodes and Edges\n",
    "    '''\n",
    "    n_nodes = 0 #Your code goes here instead of the zero\n",
    "    n_edges = 0 #Your code goes here instead of the zero\n",
    "    density = 0 #Your code goes here instead of the zero\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_directed = calculate_directed_graph_density(g_gaussian_dir)\n",
    "\n",
    "print(\"The density of the directed graph is: \",round(density_directed,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab94e0",
   "metadata": {},
   "source": [
    "In real-life, determining whether a graph is dense or sparse is quite subjective to the problem at hand. For example, we can use this metric to compare two different social networks and then compare one with each other in terms of density. Another highly used strategy to effectively measure the density of a given graph is via the comparison to multiple generated random graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b3938",
   "metadata": {},
   "source": [
    "### Homogeneous and Heterogeneous Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb7eaf",
   "metadata": {},
   "source": [
    "Last, but definitely not least, we have Homogeneous and Heterogeneous Graphs. This distinction goes into the types of both the nodes and the edges in the graph. In cases where we have only one type of node and only one type of relationship we are dealing with an Homogeneous Graph, any othe type of node or edge added would then be a Heterogeneous Graph.\n",
    "\n",
    "This is a really important distinction, because those graph are inmensely different both in their complexity -where Homogeneous Graphs tend to be much simpler-, and in the Machine Learning methodologies we can use to deal with them that we will study in later posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e012da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Inicialize a random graph\n",
    "G=nx.erdos_renyi_graph(n, 0.15,seed=45)\n",
    "\n",
    "#Assign type of node\n",
    "for u in G.nodes():\n",
    "    rand = random.randint(0, 48)\n",
    "    G.nodes[u]['Type'] = 1 if rand < 12 else 0\n",
    "\n",
    "#Draw the graph with specified colors for each node type\n",
    "color_val = [nx.get_node_attributes(G,'Type').get(node) for node in G.nodes()]\n",
    "nx.draw(G, pos, with_labels=True, node_color = color_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09947f7a",
   "metadata": {},
   "source": [
    "In this case, we construct a random graph with 25 nodes and a probability of 0.15 of having an edge between nodes. For our example, we consider a setting of a communications company where the graph considers calls between users. Particularly, the company wants to differentiate between new users (less than 12 months) and old users (more than 12 months) to understand if there are different behaviors between users.\n",
    "\n",
    "As in our example, most real-life graphs are heterogeneous graphs where different entities interact. It is quite complicated to describe a process with only one type of entity interacting with other entities all of the same type, making Heterogenous Graphs more challenging to deal with but also more expressive of the process they describe.\n",
    "\n",
    "It's also relevant to note that different type of nodes may have different characteristics or features. Think of a paper-author network, where we have author relationships between Author and Paper nodes, and citation relationships where Paper nodes connect with each other if they have cited any other paper. In this type of example, we may have really distinct feature sets between the Authors and the Papers, and as such we have to be more creative when dealing with those networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2719c28",
   "metadata": {},
   "source": [
    "NetworkX also has a number of pre-determined made Graphs, such as this one with the coappearance network of characters in the novel Les Miserables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_graph = nx.les_miserables_graph()\n",
    "nx.draw(lm_graph, with_labels=True)\n",
    "\n",
    "characters = lm_graph.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d110e9",
   "metadata": {},
   "source": [
    "Now let's try to get the neighbors of the character Myriel using a built-in function of the NetworkX Graph Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint you should transform the output of the built-in function into a list to show the results\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31216a",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "With any of the Graph Generators (https://networkx.org/documentation/stable/reference/generators.html) Create a graph of preference, and through a built-in method of the NetworkX Graph Class get the neighbors of a certain node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df4a7bd",
   "metadata": {},
   "source": [
    "## Creating Graph Based Features and enhancing ML models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4772b",
   "metadata": {},
   "source": [
    "Now let's see how we can use these new features taken from the graph to enhance our ML models. First, let's import the information of the users in the graph from the nodes_features_workshop csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/jdacevedo3010/graph-mahine-learning-workshop/raw/master/data/nodes_features_workshop.csv').set_index('USER_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b41975",
   "metadata": {},
   "source": [
    "Here we have a DataFrame with the users as the index. The columns contain the features that profile them:\n",
    "\n",
    "1. Device Type: An encoding of the different devices in the dataset\n",
    "2. Expected Value: A score that measures the value the client will bring\n",
    "3. Sales: Total amount spent by the user\n",
    "\n",
    "And a label that tells us whether the user is fraudulent or not (FRAUD column).\n",
    "\n",
    "Let's use this information to train a couple of traditional Machine Learning models such as: Gradient Boosting Trees, and Logistic Regression. Let's first create train and test masks, we will do this manually given that we wil later need this same division for the Graph Neural Networks. We will also be using torch tensors for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d266d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "def create_masks(df, seed=23, test_size=0.2):\n",
    "    '''\n",
    "    This function creates binary tensors that indicate whether an user is on the train or test set\n",
    "    '''\n",
    "    np.random.RandomState(seed)\n",
    "    temp_df = df.copy()\n",
    "    temp_df['split_flag'] = np.random.random(df.shape[0])\n",
    "    train_mask = th.BoolTensor(np.where(temp_df['split_flag'] <= (1 - test_size), True, False))\n",
    "    test_mask = th.BoolTensor(np.where((1 - test_size) < temp_df['split_flag'] , True, False))\n",
    "    return train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary masks\n",
    "train_mask, test_mask = create_masks(df, 23, 0.3)\n",
    "\n",
    "print(train_mask)\n",
    "\n",
    "#Here we transform the tensors so they indicate the indices of the train and test users instead of the binary\n",
    "train_nid = train_mask.nonzero().squeeze()\n",
    "test_nid = test_mask.nonzero().squeeze()\n",
    "\n",
    "print(train_nid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4c6d0",
   "metadata": {},
   "source": [
    "Now, let's create the X and Y tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and Y dataframes\n",
    "X = df.drop(['FRAUD'], axis=1)\n",
    "y = df.drop(['DEVICE_TYPE','EXPECTED_VALUE','SALES'], axis=1)\n",
    "\n",
    "print('The shape of the X DataFrame is: ',X.shape)\n",
    "print('The shape of the y DataFrame is: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ff17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the X and Y dataframes to tensors now as well\n",
    "X = th.tensor(X.values).float()\n",
    "y = th.tensor(y.values).type(th.LongTensor).squeeze_()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d17495",
   "metadata": {},
   "source": [
    "Let's create the functions to train the ML models, and a function that allows us to measure the performance of those models in terms of ROC Curve AUC, F1-Score, Precision and Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def get_gb_preds(X_train, y_train, X_test, seed=23):\n",
    "    clf = GradientBoostingClassifier(random_state=seed)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_probas = clf.predict_proba(X_test)\n",
    "    return y_pred_probas\n",
    "\n",
    "def get_lr_preds(X_train, y_train, X_test, seed=23):\n",
    "    clf = LogisticRegression(random_state=seed)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_probas = clf.predict_proba(X_test)\n",
    "    return y_pred_probas\n",
    "\n",
    "def get_results(y_pred_probas, y_test, threshold=0.5):\n",
    "    pred_probas_1 = y_pred_probas[:,1]\n",
    "    preds_1 = np.where(pred_probas_1>threshold,1,0)\n",
    "    auc = roc_auc_score(y_test, pred_probas_1)\n",
    "    f1 = f1_score(y_test,preds_1)\n",
    "    prec = precision_score(y_test,preds_1)\n",
    "    recall = recall_score(y_test,preds_1)\n",
    "    return auc, f1, prec, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e94bca",
   "metadata": {},
   "source": [
    "#### Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043be43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[train_nid].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'logistic-regression'\n",
    "y_pred_probas = get_lr_preds(X[train_nid], y[train_nid], X[test_nid], seed=23)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model','AUC','F1 Score','Precision','Recall'])\n",
    "auc, f1, prec, recall = get_results(y_pred_probas, y[test_nid], 0.5)\n",
    "dict_results = {'Model':model, 'AUC':auc, 'F1 Score':f1, 'Precision':prec, 'Recall':recall}\n",
    "results_df = results_df.append(dict_results, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623b31b",
   "metadata": {},
   "source": [
    "#### GBoost results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'GBoost'\n",
    "y_pred_probas = get_gb_preds(X[train_nid], y[train_nid], X[test_nid], seed=23)\n",
    "\n",
    "auc, f1, prec, recall = get_results(y_pred_probas, y[test_nid], 0.5)\n",
    "dict_results = {'Model':model, 'AUC':auc, 'F1 Score':f1, 'Precision':prec, 'Recall':recall}\n",
    "results_df = results_df.append(dict_results, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138f6f3",
   "metadata": {},
   "source": [
    "## Creating a Graph from own data using NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7b8d",
   "metadata": {},
   "source": [
    "We will know see how to create a graph from data instead of randomly. For this we will have to import the csv's in the data folder and process them for NetworkX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a961e",
   "metadata": {},
   "source": [
    "First lets import the relations csv in the data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edges_df = pd.read_csv('https://github.com/jdacevedo3010/graph-mahine-learning-workshop/raw/master/data/new_edges_workshop.csv')\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53582be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20e03b",
   "metadata": {},
   "source": [
    "Here you a 2-colummn DataFrame that contains the undirected edges between distinct users. This is normally referred to as \"List of edges\" and it's a common way to create graphs. NetworkX also has a method to create a graph from a DataFrame of edges, let's do just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf4f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edges_df,'~from','~to')\n",
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27856d06",
   "metadata": {},
   "source": [
    "Let's draw a portion of the graph to check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_draw = nx.from_pandas_edgelist(edges_df.head(100),'~from','~to')\n",
    "nx.draw(G_draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6165be",
   "metadata": {},
   "source": [
    "Nice! We can now use this created graph to extract characteristics from it. \n",
    "\n",
    "Let's say we want to get the number of neighbors of each node in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(G.degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401329e",
   "metadata": {},
   "source": [
    "We can use the degree method in NetworkX to create a dictionary that holds the node id's as the keys and the degree of that node as the value. There are also plenty of other measures, we can extract from the Graph object of NetworkX like centrality or betweeness metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1237cc",
   "metadata": {},
   "source": [
    "More information about the NetworkX library can be found in this tutorial: https://networkx.org/nx-guides/content/tutorial.html. Or in the overall documentation guide of the package: https://networkx.org/nx-guides/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02facc",
   "metadata": {},
   "source": [
    "#### And now let's enhance the features with some extracted from the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcecb90",
   "metadata": {},
   "source": [
    "Now we will use the previously generated dictionary of degrees as an additional feature to the DataFrame, along with the centrality measure PageRank.\n",
    "\n",
    "PageRank was developed by Google and measures the importance of a node in a Graph given how connected are the node's neighbors. More information can be found here: https://es.wikipedia.org/wiki/PageRank\n",
    "\n",
    "Let's first calculate that for the previously generated graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ba92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G,alpha=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f1b40",
   "metadata": {},
   "source": [
    "Let's take a look at why those values for two nodes are so different. First, we will select a high PageRank node and a low PageRank node. Then, we need to get the 2-hop neighbors of those nodes in a list using the neighbors() method (https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.neighbors.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The PageRank of the selected highly central node is: ',pr[38709])\n",
    "print('The PageRank of the selected lowly central node is: ',pr[125388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69911eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_2d_list(matrix):\n",
    "    flatten_matrix = []\n",
    "    for sublist in matrix:\n",
    "        for val in sublist:\n",
    "            flatten_matrix.append(val)\n",
    "    return flatten_matrix\n",
    "\n",
    "high_neighbors = [n for n in G.neighbors(38709)]\n",
    "high_neighbors_2 = flatten_2d_list([[n for n in G.neighbors(n2)] for n2 in high_neighbors])\n",
    "low_neighbors = [n for n in G.neighbors(125388)]\n",
    "low_neighbors_2 = flatten_2d_list([[n for n in G.neighbors(n2)] for n2 in low_neighbors])\n",
    "\n",
    "\n",
    "print(\"Number of 2-hop neighbors of high PageRank: \",len(high_neighbors_2))\n",
    "print(\"Number of 2-hop neighbors of low PageRank: \", len(low_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f73a7",
   "metadata": {},
   "source": [
    "As mentioned before, the PageRank measures the centrality of a node given the connections of his neighbors. So in a social network, if my friends have many friends then I'll be a highly central node.\n",
    "\n",
    "Now let's draw those subgraphs using the subgraph method of networkx (https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.subgraph.html) for a better look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G.subgraph(high_neighbors_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G.subgraph(low_neighbors_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943e9be",
   "metadata": {},
   "source": [
    "We can see that the highly central node has every node highly interconnected with each other, while the low PageRank node has a cluster in the middle and the a satelite circunference around that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223be7",
   "metadata": {},
   "source": [
    "And now let's add both the degree and PageRank as features for the users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Degree and PageRank into the DataFrame\n",
    "df_enhanced = df.copy()\n",
    "df_enhanced['DEGREE'] = df.index.map(degrees)\n",
    "df_enhanced['PAGERANK'] = df.index.map(pr)\n",
    "\n",
    "df_enhanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad14256e",
   "metadata": {},
   "source": [
    "And finally, let's run the same models as before with these new features to see how the results compare with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and Y dataframes\n",
    "X_enhanced = df_enhanced.drop(['FRAUD'], axis=1).fillna(0)\n",
    "y_enhanced = df_enhanced.drop(['DEVICE_TYPE','EXPECTED_VALUE','SALES','DEGREE','PAGERANK'], axis=1)\n",
    "\n",
    "print('The shape of the X DataFrame is: ',X.shape)\n",
    "print('The shape of the y DataFrame is: ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6734b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_enhanced[['DEGREE','PAGERANK']] = scaler.fit_transform(X_enhanced[['DEGREE','PAGERANK']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.tensor(X_enhanced.values).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11456462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the X and Y dataframes to tensors now as well\n",
    "X_enhanced = th.tensor(X_enhanced.values).float()\n",
    "y_enhanced = th.tensor(y_enhanced.values).type(th.LongTensor).squeeze_()\n",
    "\n",
    "print(X_enhanced.shape)\n",
    "print(y_enhanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff314e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = 'logistic-regression-enhanced'\n",
    "y_pred_probas = get_lr_preds(X_enhanced[train_nid], y_enhanced[train_nid], X_enhanced[test_nid], seed=23)\n",
    "\n",
    "auc, f1, prec, recall = get_results(y_pred_probas, y_enhanced[test_nid], 0.5)\n",
    "dict_results = {'Model':model, 'AUC':auc, 'F1 Score':f1, 'Precision':prec, 'Recall':recall}\n",
    "results_df = results_df.append(dict_results, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'GBoost-enhanced'\n",
    "y_pred_probas = get_gb_preds(X_enhanced[train_nid], y_enhanced[train_nid], X_enhanced[test_nid], seed=23)\n",
    "\n",
    "auc, f1, prec, recall = get_results(y_pred_probas, y_enhanced[test_nid], 0.5)\n",
    "dict_results = {'Model':model, 'AUC':auc, 'F1 Score':f1, 'Precision':prec, 'Recall':recall}\n",
    "results_df = results_df.append(dict_results, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6f34c",
   "metadata": {},
   "source": [
    "It looks like in this case the new added features from the graph are not achieving a better performance for the Machine Learning model, this could be due to the model already doind a pretty good job with the non-graph features and because of the social graph not provding usefull information for fraude detection that makes sense given that fraudulents probably would try to hide from connections. Maybe another type of graph can be better to this task.\n",
    "\n",
    "Given the rarity of these Graph-Based Features they carry vastly different information from the tipically used features and as such allow the model to better differentiate classes, that can lead to better performance in models.This conclusions is further developed on our previously published paper: Supporting Financial Inclusion with Graph Machine Learning and Super-App Alternative Data; where we prove how graph based features augments the AUC of Credit RIsk models up to 4-5 percentage points!\n",
    "\n",
    "https://arxiv.org/abs/2102.09974\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c61ce",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/jdacevedo3010/graph-mahine-learning-workshop/master/images/paper_performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea04877",
   "metadata": {},
   "source": [
    "The above Figure is taken from the paper, there, the authors show how Graph-Based Features Enhanced models improve the results in terms of predicting credit default over non-Grap-based features models (Base in the figure). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d46f93",
   "metadata": {},
   "source": [
    "Now you can try adding any graph based feature you can think of and repeat the process to see if the performance improves.\n",
    "\n",
    "Hint: It doesn't have to be a graph Algorithm like pagerank or the degree, it can be something based on a personalized query. Think of the problem you are solving and what could add information from a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ee053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to use as many cells below as you need"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "af92ff48b314d6de65d7d307803e052e27c55ee0db97487118890f19379fef9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
